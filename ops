{"version":1,"ops":[{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575897536,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzIzNDQyMA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563234420"},"message":"I guess this is actually a https://github.com/ajayyy/SponsorBlockServer issue, though there seem to be other server related issues in this repo?","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1575898000,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzIzNzUyNw==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563237527"},"message":"This actually is on my to-do list (after switching the DB to WAL mode), but\nit's good to have a formal issue here for it. Thanks!\n\nOn Mon, Dec 9, 2019, 8:18 AM phiresky, \u003cnotifications@github.com\u003e wrote:\n\n\u003e I guess this is actually a https://github.com/ajayyy/SponsorBlockServer\n\u003e issue, though there seem to be other server related issues in this repo?\n\u003e\n\u003e â€”\n\u003e You are receiving this because you are subscribed to this thread.\n\u003e Reply to this email directly, view it on GitHub\n\u003e \u003chttps://github.com/ajayyy/SponsorBlock/issues/186?email_source=notifications\u0026email_token=ADAZV4CHEOFUZKSD4LGFSFDQXZAUBA5CNFSM4JYJACDKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEGJEM5A#issuecomment-563234420\u003e,\n\u003e or unsubscribe\n\u003e \u003chttps://github.com/notifications/unsubscribe-auth/ADAZV4ABDE7YN54CHAR56ZDQXZAUBANCNFSM4JYJACDA\u003e\n\u003e .\n\u003e","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1575898137,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzIzODQ0Nw==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563238447"},"message":"I think it is more popular due to being the first in the search results :)","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575898659,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI0MTc5NQ==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563241795"},"message":"I was actually about to open another issue about WAL mode :) \n\nHere are some more suggestions for sqlite performance, apart from `pragma journal_mode = WAL;`:\n\n1. `pragma synchronous = normal;` or even `off`. `normal` is still completely corruption safe in WAL mode. `off` *can* cause db corruption though I've never had problems. See here: https://www.sqlite.org/pragma.html#pragma_synchronous\n3. `pragma optimize` _To achieve the best long-term query performance without the need to do a detailed engineering analysis of the application schema and SQL, it is recommended that applications run \"PRAGMA optimize\" (with no arguments) just before closing each database connection. Long-running applications might also benefit from setting a timer to run \"PRAGMA optimize\" every few hours._ https://www.sqlite.org/pragma.html#pragma_optimize\n2. `pragma temp_store = memory;` not sure how much this one helps.\n3. `pragma page_size = 32768;` this improved performance and db size *a lot* for me in one project, but that might only be true because i was storing somewhat large blobs in my database and might not be good for this project where rows are small. \n\nThen there's also auto_vacuum but I think that's only really useful if you delete rows regularily. It also slows down write queries unless you use `pragma auto_vacuum=incremental` and then run `pragma incremental_vacuum` sometimes.","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1575898838,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI0Mjk4Ng==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563242986"},"message":"I was having trouble getting Wal mode to do resyncs (putting it back in the main file, not sure what the name is) at a consistent rate. I also couldn't figure out how to trigger it manually.\n\nSince I am hosting the .db file for download, I want to to be updated at least every few minutes.","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575899011,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI0NDEwNA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563244104"},"message":"Not an expert, but as far as i know you can run `PRAGMA schema.wal_checkpoint`; to force it to write data to .db file right now. You can also change how often it resyncs normally with `PRAGMA wal_autocheckpoint = N` where N is the number of pages. That's not really a predictable time though since that means it will write changes to db after every N * 4096 bytes not after N seconds","files":null},{"type":6,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575899011,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMyMTc0MDcyOQ=="},"target":"2d001427223942571cfc3dde653b17321c01d63775d6d275a06491289210e9d3","message":"Not an expert, but as far as i know you can run `PRAGMA wal_checkpoint`; to force it to write data to .db file right now. You can also change how often it resyncs normally with `PRAGMA wal_autocheckpoint = N` where N is the number of pages. That's not really a predictable time though since that means it will write changes to db after every N * 4096 bytes not after N seconds","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575899076,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI0NDY1NA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563244654"},"message":"source:\n\nhttps://www.sqlite.org/pragma.html#pragma_wal_checkpoint\nand here:\n\n\u003e one wants to eventually transfer all the transactions that are appended in the WAL file back into the original database. Moving the WAL file transactions back into the database is called a \"checkpoint\". [src](https://www.sqlite.org/wal.html#ckpt)","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1575899173,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI0NTMyMw==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563245323"},"message":"Yep, I have to play around with it more since I couldn't get that command working","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575899285,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI0NjA4MA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563246080"},"message":"Note that it won't actually delete or even truncate the wal file if you have more than one process that has the db open (probably unless you do `pragma wal_checkpoint(full);` but i don't think you want that)","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575899856,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI0OTg1NQ==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563249855"},"message":"Another thing: Looks like you don't have any indices on the columns you're using frequently? That intentional?\n\ne.g. doing\n`create index sponsorTimes_videoID on sponsorTimes(videoID);`\n\nreduces duration of\n`SELECT startTime, endTime, votes, UUID, shadowHidden FROM sponsorTimes WHERE videoID = '7HXqkjWS2po' ORDER BY startTime`\n\nfrom 15ms to 2ms for me.","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1575899963,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI1MDU3OA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563250578"},"message":"Is there a disadvantage to this? Does it hurt write time?","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575900165,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI1MTk4NA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563251984"},"message":"To indices? Yes, the index is (I think) a separate copy of the indexed column(s) in a B-Tree that needs to be updated on writes (though only on ones that change the indexed columns, which in this case should only be the first time a new video is added). For most applications the consensus is that it's definitely worth it. In this case it should be as well, since probably you have many many more reads than writes, especially since you also have tons of queries where no entries even exist that currently still take 15ms of your CPU time every time.","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1575900340,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI1MzE0NQ==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563253145"},"message":"Okay, then I think that should be saved until after wal mode","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1575900474,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI1NDA0Mw==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563254043"},"message":"https://stackoverflow.com/a/765696","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575900557,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI1NDU4MQ==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563254581"},"message":"Yeah i actually did that to check if it was doing a full table scan before adding the index and to check if it was using it afterwards: \n![image](https://user-images.githubusercontent.com/2303841/70442085-dd17df80-1a95-11ea-83f0-2cab62105352.png)\n\n\u003e Does it hurt write time?\n\nActually from what I see it should improve write times a lot at least for `/api/postVideoSponsorTimes`, since that also does multiple SELECT queries that need to scan the whole sponsorTimes table every time that can be sped up with a sponsorTimes(videoId) index.","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575901486,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzI2MTQ1Ng==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563261456"},"message":"Another thing you should probably do more for data integrity reasons than performance is add some keys to your database.\n\nFor example from what I see right now you have a race condition here: https://github.com/ajayyy/SponsorBlockServer/blob/master/index.js#L304-L308\nSince you actually do the select first and then update so if you submit the same vote multiple times in quick succession you should be able to get multiple entries into that database.\n\n\nSuggestion:\n\n\n```diff\ndiff --git a/databases/_private.db.sql b/databases/_private.db.sql\nindex dfd672a..af89fa2 100644\n--- a/databases/_private.db.sql\n+++ b/databases/_private.db.sql\n@@ -1,12 +1,13 @@\n BEGIN TRANSACTION;\n CREATE TABLE IF NOT EXISTS \"shadowBannedUsers\" (\n-\t\"userID\"\tTEXT NOT NULL\n+\t\"userID\"\tTEXT NOT NULL PRIMARY KEY\n );\n CREATE TABLE IF NOT EXISTS \"votes\" (\n \t\"UUID\"\tTEXT NOT NULL,\n \t\"userID\"\tINTEGER NOT NULL,\n \t\"hashedIP\"\tINTEGER NOT NULL,\n-\t\"type\"\tINTEGER NOT NULL\n+\t\"type\"\tINTEGER NOT NULL,\n+\tPRIMARY KEY (\"UUID\", \"userID\") -- only one entry per user and sponsor UUID\n );\n CREATE TABLE IF NOT EXISTS \"sponsorTimes\" (\n \t\"videoID\"\tTEXT NOT NULL,\ndiff --git a/databases/_sponsorTimes.db.sql b/databases/_sponsorTimes.db.sql\nindex 647d40c..6c94775 100644\n--- a/databases/_sponsorTimes.db.sql\n+++ b/databases/_sponsorTimes.db.sql\n@@ -1,20 +1,20 @@\n BEGIN TRANSACTION;\n CREATE TABLE IF NOT EXISTS \"vipUsers\" (\n-\t\"userID\"\tTEXT NOT NULL\n+\t\"userID\"\tTEXT NOT NULL PRIMARY KEY\n );\n CREATE TABLE IF NOT EXISTS \"sponsorTimes\" (\n \t\"videoID\"\tTEXT NOT NULL,\n \t\"startTime\"\tREAL NOT NULL,\n \t\"endTime\"\tREAL NOT NULL,\n \t\"votes\"\tINTEGER NOT NULL,\n-\t\"UUID\"\tTEXT NOT NULL UNIQUE,\n+\t\"UUID\"\tTEXT NOT NULL PRIMARY KEY,\n \t\"userID\"\tTEXT NOT NULL,\n \t\"timeSubmitted\"\tINTEGER NOT NULL,\n \t\"views\"\tINTEGER NOT NULL,\n \t\"shadowHidden\"\tINTEGER NOT NULL\n );\n CREATE TABLE IF NOT EXISTS \"userNames\" (\n-\t\"userID\"\tTEXT NOT NULL,\n+\t\"userID\"\tTEXT NOT NULL PRIMARY KEY,\n \t\"userName\"\tTEXT NOT NULL\n );\n COMMIT;\n```\n\nNote that PRIMARY KEY implies UNIQUE which also automatically creates an index on that key (which improves performance for `SELECT where` that column.","files":null},{"type":6,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1575901486,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMyMTc2Nzg4OQ=="},"target":"7c20eca53d953433ed0d004449477d1b94d42a3d08223d06c603c3fec336f9ef","message":"Another thing you should probably do more for data integrity reasons than performance is add some keys to your database.\n\nFor example from what I see right now you have a race condition here: https://github.com/ajayyy/SponsorBlockServer/blob/master/index.js#L304-L308\nSince you actually do the select first and then update if you submit the same vote multiple times in quick succession you should be able to get multiple entries into that database.\n\n\nSuggestion:\n\n\n```diff\ndiff --git a/databases/_private.db.sql b/databases/_private.db.sql\nindex dfd672a..af89fa2 100644\n--- a/databases/_private.db.sql\n+++ b/databases/_private.db.sql\n@@ -1,12 +1,13 @@\n BEGIN TRANSACTION;\n CREATE TABLE IF NOT EXISTS \"shadowBannedUsers\" (\n-\t\"userID\"\tTEXT NOT NULL\n+\t\"userID\"\tTEXT NOT NULL PRIMARY KEY\n );\n CREATE TABLE IF NOT EXISTS \"votes\" (\n \t\"UUID\"\tTEXT NOT NULL,\n \t\"userID\"\tINTEGER NOT NULL,\n \t\"hashedIP\"\tINTEGER NOT NULL,\n-\t\"type\"\tINTEGER NOT NULL\n+\t\"type\"\tINTEGER NOT NULL,\n+\tPRIMARY KEY (\"UUID\", \"userID\") -- only one entry per user and sponsor UUID\n );\n CREATE TABLE IF NOT EXISTS \"sponsorTimes\" (\n \t\"videoID\"\tTEXT NOT NULL,\ndiff --git a/databases/_sponsorTimes.db.sql b/databases/_sponsorTimes.db.sql\nindex 647d40c..6c94775 100644\n--- a/databases/_sponsorTimes.db.sql\n+++ b/databases/_sponsorTimes.db.sql\n@@ -1,20 +1,20 @@\n BEGIN TRANSACTION;\n CREATE TABLE IF NOT EXISTS \"vipUsers\" (\n-\t\"userID\"\tTEXT NOT NULL\n+\t\"userID\"\tTEXT NOT NULL PRIMARY KEY\n );\n CREATE TABLE IF NOT EXISTS \"sponsorTimes\" (\n \t\"videoID\"\tTEXT NOT NULL,\n \t\"startTime\"\tREAL NOT NULL,\n \t\"endTime\"\tREAL NOT NULL,\n \t\"votes\"\tINTEGER NOT NULL,\n-\t\"UUID\"\tTEXT NOT NULL UNIQUE,\n+\t\"UUID\"\tTEXT NOT NULL PRIMARY KEY,\n \t\"userID\"\tTEXT NOT NULL,\n \t\"timeSubmitted\"\tINTEGER NOT NULL,\n \t\"views\"\tINTEGER NOT NULL,\n \t\"shadowHidden\"\tINTEGER NOT NULL\n );\n CREATE TABLE IF NOT EXISTS \"userNames\" (\n-\t\"userID\"\tTEXT NOT NULL,\n+\t\"userID\"\tTEXT NOT NULL PRIMARY KEY,\n \t\"userName\"\tTEXT NOT NULL\n );\n COMMIT;\n```\n\nNote that PRIMARY KEY implies UNIQUE which also automatically creates an index on that key (which improves performance for `SELECT where` that column.","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1575927936,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2MzQ1NDQxNg==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-563454416"},"message":"Wouldn't this just cause a crash instead. That is what was happening in `postSponsorTimes` which uses `UNIQUE` when requests were too fast.","files":null},{"type":2,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1575999205,"metadata":{"github-id":"MDE3OlJlbmFtZWRUaXRsZUV2ZW50Mjg3MTQyNTc5Ng=="},"title":"Better-sqlite3 and WAL mode","was":"Better-sqlite3 and other improvements"},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1576161479,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2NTAzMjkwNg==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-565032906"},"message":"you mean would the schema change just cause a crash instead? not sure, the INSERT query would be rejected but in this case since the callback is missing it would probably just be ignored. (not wanted since the code below that insert should only happen if the insert succeeded)","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1576173850,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2NTExODMxMw==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-565118313"},"message":"using `INSERT` with a duplicate `UNIQUE` value causes a crash. I can catch it though.","files":null},{"type":5,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1576300771,"metadata":{"github-id":"MDEyOkxhYmVsZWRFdmVudDI4ODMxODI5NDA="},"added":["HIGH PRIORITY"],"removed":[]},{"type":3,"author":{"id":"b14cc2768aa2382d12c2fe981a4f5892f9a6aece"},"timestamp":1577820133,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2OTk3ODExNQ==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-569978115"},"message":"Not sure if this is the right place to say this but, imo, the production database should _eventually_ be migrated to mysql (mariadb) or postgresql. Sqlite is not meant for large databases. It's [supposed](https://www.sqlite.org/whentouse.html) to be used for small projects or user applications. I suspect that the database is going to get much larger very quickly, and queries will get slower and slower. I'm not sure how many hits per day your database is queried, but you're probably going to be fine for a while. Again, not soon, but eventually.","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1577822251,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2OTk4MjE1Ng==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-569982156"},"message":"@jplsek Right now the main draw to sqlite is being able to share a [single file](http://sponsor.ajay.app/database.db) to let others access the raw database. So, I do want to keep it sqlite for as long as possible.","files":null},{"type":6,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1577822251,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMzMTM3MzUwMQ=="},"target":"e95f2d321ad0d1d2c54f2cd69f3afaae8d085177c0cab030f805d967ab06c3bb","message":"@jplsek Right now the main draw to sqlite is being able to share a [single file](http://sponsor.ajay.app/database.db) to let others access the raw database. So, I do want to keep it sqlite for as long as possible. This can be achieved in other ways however such as automated backups to a file.","files":null},{"type":3,"author":{"id":"b14cc2768aa2382d12c2fe981a4f5892f9a6aece"},"timestamp":1577831392,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU2OTk5OTc1Ng==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-569999756"},"message":"That's what a [database dump](https://mariadb.com/kb/en/mysqldump/) is for. :)","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1578048559,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3MDUzODM1OA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-570538358"},"message":"@jplsek imo you're underestimating the scalability of sqlite. Sqlite works just fine for 10k+ selects per second and 100+ inserts per second. It also works fine for db sizes of 1GB+. The current DB has 33k videos and is 14MB in size. So if it grew to 1GB that would be space for 2.2 million videos. Also you're somewhat mistaken in that queries will get slower and slower if the db size grows.\n\nIf the server has enough RAM (and if the mmap pragma is set) select queries will stay pretty much the same performance regardless of the db size since it's just a lookup in RAM, same as now, and same as it would be for other DB engines. Afaik it's a btree lookup into the index (log(size)) + a linear search in the WAL log (const time). Inserts will get slower since it has to rewrite larger indices and table data, but this application is very much read-heavy.\n\nSadly the [speed](https://www.sqlite.org/speed.html) page is very outdated so it's not that useful to reference. [The \"FS\" page](https://www.sqlite.org/fasterthanfs.html) is newer but not as relevant.\n\nA better reason to switch to eg PostgreSQL would be the pretty bad support for SQL in sqlite and the possibility for replication to different servers.\n\nAlso database dumps are pretty ugly most of the time you see them, since they either are borked csv files or in a internal database format only a specific db engine can understand (i've fought with scripts to convert MySQL dumps to csv or sqlite dumps but they never worked on the first try)","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1578861724,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3MzQ1NTA2Mg==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-573455062"},"message":"One more thing i forgot @ajayyy: You should also set `pragma mmap_size= 30000000000;` cuz fast","files":null},{"type":3,"author":{"id":"937f912fe8c6fbde432505781ebabd3a403786f7"},"timestamp":1578951542,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3Mzg4MjIzMw==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-573882233"},"message":"Seems like a big number does it need to be set at 30GB\nStill think a Redis database would be better.\nAs there is cluster support and its in ram (Still able to have data in a file as well)","files":null},{"type":6,"author":{"id":"937f912fe8c6fbde432505781ebabd3a403786f7"},"timestamp":1578951542,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMzNzA0MDIwOA=="},"target":"0b3100efa1df6aeb406d4f02be8e07282e38fc7e3c0b0fe2f9901a194e5838ff","message":"Seems like a big number does it need to be set at 30GB\nStill think a Redis database would be better.\nAs there is cluster support and its in ram (Still able to have data in a file as well)\nIts also possible to still use SQL with https://redislabs.com/blog/get-sql-like-experience-redis/","files":null},{"type":6,"author":{"id":"937f912fe8c6fbde432505781ebabd3a403786f7"},"timestamp":1578951645,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMzNzA0MTEzOA=="},"target":"0b3100efa1df6aeb406d4f02be8e07282e38fc7e3c0b0fe2f9901a194e5838ff","message":"Seems like a big number does it need to be set at 30GB\nStill think a [Redis](https://redis.io/) database would be better.\nAs there is [cluster support](https://redis.io/topics/cluster-tutorial) and its in ram (Still able to have data in a file as well)\nIts also possible to still use SQL with [RedisLabs ~ get sql like experience](https://redislabs.com/blog/get-sql-like-experience-redis/)","files":null},{"type":6,"author":{"id":"937f912fe8c6fbde432505781ebabd3a403786f7"},"timestamp":1578951697,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMzNzA0MTYwNQ=="},"target":"0b3100efa1df6aeb406d4f02be8e07282e38fc7e3c0b0fe2f9901a194e5838ff","message":"Seems like a big number does it need to be set at 30GB\nStill think a [Redis](https://redis.io/) database would be better.\nAs there is [cluster support](https://redis.io/topics/cluster-tutorial) and its in ram [(Still able to have data in a file as well)](https://redis.io/topics/persistence)\nIts also possible to still use SQL with [RedisLabs ~ get sql like experience](https://redislabs.com/blog/get-sql-like-experience-redis/)","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1578994616,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3NDA4NjQ0Ng==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-574086446"},"message":"Na, redis is definitely not made for something like this. Even calling it a \"database\" is really misleading. It's a server that keeps a huge hashmap in RAM and dumps it to disk every 30 seconds.","files":null},{"type":6,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1578994616,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMzNzMzNjEyMQ=="},"target":"696914ddbaeab974fbcfa4aa4a83d32668f3788d9b068b1545f97cd7ca088203","message":"Na, redis is definitely not made for something like this. Even calling it a \"database\" is really misleading. It's a server that keeps a huge hashmap in RAM and dumps it to disk every 30 seconds.\n\nNo tables at all, no data structures, no integrity guarantees and no transactions.","files":null},{"type":6,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1578994679,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMzNzMzNjgzMg=="},"target":"696914ddbaeab974fbcfa4aa4a83d32668f3788d9b068b1545f97cd7ca088203","message":"No reason not to set it as a large number. \n\nAnd na, redis is definitely not made for something like this. Even calling it a \"database\" is really misleading. It's a server that keeps a huge hashmap in RAM and dumps it to disk every 30 seconds.\n\nNo tables at all, no data structures, no integrity guarantees and no transactions.","files":null},{"type":3,"author":{"id":"937f912fe8c6fbde432505781ebabd3a403786f7"},"timestamp":1579202586,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3NTMwNDA4Mw==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-575304083"},"message":"@phiresky \n\"Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker\" from `https://redis.io/topics/introduction` This seems to mean that it maybe used as a database.\n\nAlso it does seem to have [transactions](https://redis.io/topics/transactions)\nAnd for data structures: \"It supports data structures such as strings, hashes, lists, sets, sorted sets\"\n\nIt does not use tables like in SQL however that does not seem to be a bad thing.\n\nIt also seems like a \"Append-only file\" will run when \"Redis receives a command that changes the dataset\" instead of having to wait.","files":null},{"type":6,"author":{"id":"937f912fe8c6fbde432505781ebabd3a403786f7"},"timestamp":1579202586,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMzOTEwMjYzMQ=="},"target":"99154097cf9cc551a07ddf9dfadea8bb86d57f2d8284079c85d79208f663156b","message":"@phiresky \n\"Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker\" from [introduction](https://redis.io/topics/introduction) This seems to mean that it maybe used as a database.\n\nAlso it does seem to have [transactions](https://redis.io/topics/transactions)\nAnd for data structures: \"It supports data structures such as strings, hashes, lists, sets, sorted sets\"\n\nIt does not use tables like in SQL however that does not seem to be a bad thing.\n\nIt also seems like a \"Append-only file\" will run when \"Redis receives a command that changes the dataset\" instead of having to wait.","files":null},{"type":6,"author":{"id":"937f912fe8c6fbde432505781ebabd3a403786f7"},"timestamp":1579202739,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMzOTEwNDE2NQ=="},"target":"99154097cf9cc551a07ddf9dfadea8bb86d57f2d8284079c85d79208f663156b","message":"@phiresky \n\"Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker\" from [introduction](https://redis.io/topics/introduction) This seems to mean that it maybe used as a database.\n\nAlso it does seem to have [transactions](https://redis.io/topics/transactions)\nAnd for data structures: \"It supports data structures such as strings, hashes, lists, sets, sorted sets\"\n\nIt does not use tables like in SQL however that does not seem to be a bad thing.\n\nIt also seems like a \"Append-only file\" will run when \"Redis receives a command that changes the dataset\" instead of having to wait. may be used.","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1579202962,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3NTMwNzU4MA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-575307580"},"message":"I know what redis is, I'm using it for sessions, caching and message passing right now in a production site (3M keys and ~20 events per second). Including the .multi() thing which is stop-the-world-\"transactions\" and the to-disk serialization. It works ok. I'd still definitely not use it for this, though I'm not really willing to spend more time explaining why unless ajayyy decides to seriously consider it for this.","files":null},{"type":3,"author":{"id":"937f912fe8c6fbde432505781ebabd3a403786f7"},"timestamp":1579203191,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3NTMwOTIzNQ==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-575309235"},"message":"Is there a problem with persistence?","files":null},{"type":3,"author":{"id":"937f912fe8c6fbde432505781ebabd3a403786f7"},"timestamp":1579203865,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3NTMxMzU2Mg==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-575313562"},"message":"https://github.com/RedBeardLab/rediSQL (never used it)","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1579810009,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3Nzg1MzAyMQ==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-577853021"},"message":"After doing some testing, I feel confident to enabled WAL mode.\n\nI took me long enough haha.","files":null},{"type":2,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1579810019,"metadata":{"github-id":"MDE3OlJlbmFtZWRUaXRsZUV2ZW50Mjk3NTEwMDExNA=="},"title":"Better-sqlite3 and other improvements","was":"Better-sqlite3 and WAL mode"},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1579810202,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3Nzg1NDM4OA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-577854388"},"message":"Hmm, the page limit didn't seem to work. The WAL file is growing fast.","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1579956414,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3ODQwMzQ5NQ==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-578403495"},"message":"So you set wal_autocheckpoint to some lower value? \n\nI think the size of the WAL file is not necessarily indicative of the amount of unwritten data, since I think the WAL file is only truncated in some situations but not when the data is committed. For example, if you run `pragma wal_checkpoint(full)` the WAL file won't change size if other processes have the file open but still commit everything, only if you run `pragma wal_checkpoint(truncate)` it will block other processes and reset the WAL file to zero bytes.","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1579964346,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3ODQxMzAwMQ==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-578413001"},"message":"@phiresky okay. I guess I can shutdown the server for a few seconds and do that when it gets too big","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1579964412,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3ODQxMzA5Ng==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-578413096"},"message":"@ajayyy you don't have to shut down the server to run `pragma wal_checkpoint(truncate)` i think. it will just lock out writes until done (\u003c1s)","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1579964450,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3ODQxMzE1MA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-578413150"},"message":"@phiresky oh okay, so reads are fine?","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1579964524,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3ODQxMzI0Mw==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-578413243"},"message":"Not sure actually. But even if they have to wait it's still better than shutting down the server right?\n\nBut also, you shouldn't have to run that at all, the WAL file size shouldn't really matter. I think you can check how many pages are actually uncommitted by looking at the second column of the output of `pragma wal_checkpoint`","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1579964606,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3ODQxMzMzMw==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-578413333"},"message":"In my experience, doing this crashes the server anyway. Maybe that is because the default timeout is very small though","files":null},{"type":6,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1579964606,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDM0MzY3NDMyMg=="},"target":"df32248770049bdcaa7be4f1faacf9af86749141050408f0ad5fae173b8d429e","message":"In my experience, doing this crashes the server anyway. Maybe that is because the default timeout is very small though \n\nThe WAL size is currently higher than the DB size","files":null},{"type":6,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1579964638,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDM0MzY3NDM4NQ=="},"target":"df32248770049bdcaa7be4f1faacf9af86749141050408f0ad5fae173b8d429e","message":"In my experience, doing this crashes the server anyway. Maybe that is because the default timeout is very small though \n\nThe WAL size is currently higher than the DB size. However, that doesn't mean it is all uncommitted","files":null},{"type":3,"author":{"id":"8e682db7433006d2fb0f6f5aeded50c287306d2f"},"timestamp":1579964748,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3ODQxMzYxMQ==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-578413611"},"message":"It crashes the whole server? It should at the most make the db reject read and write operations, whose errors should be handled in the code right? i.e. write (+maybe read) requests would fail but the server should stay up. With what error does it crash?","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1579964935,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU3ODQxMzkwNA==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-578413904"},"message":"The errors are catched in my BetterSqlite PR, so this might not happen anymore","files":null},{"type":3,"author":{"id":"969fe24ee4082d52977026a04efd671fd5270344"},"timestamp":1583190002,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU5MzY2NzYwMw==","github-url":"https://github.com/ajayyy/SponsorBlock/issues/186#issuecomment-593667603"},"message":"Enabling mmap was a great improvement.","files":null}]}